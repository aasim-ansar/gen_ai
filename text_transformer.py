# -*- coding: utf-8 -*-
"""text_transformer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nNvpRSYizJ7SOYDA49hTxPPyzkIAvfoi
"""

!pip install transformers torch

from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load the pre-trained GPT-2 tokenizer and model
model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

input_text = "Once upon a time"
input_ids = tokenizer.encode(input_text, return_tensors="pt")

output = model.generate(
    input_ids,          # input prompt
    max_length=100,     # maximum length of generated text
    num_return_sequences=1,  # number of outputs
    no_repeat_ngram_size=2,  # avoid repeating phrases
    temperature=0.7,         # creativity of output (0.1-1.0)
    top_k=50,                 # only consider top_k words at each step
    top_p=0.95                # nucleus sampling
)

generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
print(generated_text)

